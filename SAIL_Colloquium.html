<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/benjamin.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<div data-id="1" class="header-left" data-auto-animate>
					SAIL Colloquium 
				</div>
				<div data-id="2" class="header-right" data-auto-animate>
					<em>Bhargav Acharya</em> &bullet; 15. May 2024
				</div>
				<div class="footer-left">
					<img src="Images/1024px-UniversitaÃàt_Bielefeld_Logo.svg" height="25" style="margin-right: 10px;">
				</div>
				<!-- Intro -->
					<!-- TODO find better background style -->
				<section data-state="titleslide" data-auto-animate >
						<h2>
							<div data-id="1" style="display: inline;">
								SAIL Colloquium
							</div>
						</h2>
						<h3>
							Generalization of Video-Based Heart Rate Estimation Methods To
Low Illumination and Elevated Heart Rates
							<!-- Heart Rate Estimation From Videos -->
						</h3>
						<h4>
							<div data-id="2"> Bhargav Acharya </div>
						<h4>
							<div data-id="2"> 15 May 2024 </div>
						</h4>
				</section>
				<!-- <section data-auto-animate class="text-left"> -->
					<!-- <h3 >  -->
						<!-- <div data-id="3" style="display: inline;"> Introduction</div> -->
					<!-- </h3> -->
				<!-- </section> -->
				<!--Recap-->
				<section data-auto-animate class="text-left">
					<h3 > 
						<div data-id="3" style="display: inline;"> Introduction </div>
					</h3>
					<ul> 
					  <li class="fragment" data-fragment-index="1" > Photophlethosmogrpahy(PPG) </li>
					  <figure> 
					  <div class="fragment" data-fragment-index="1">
							<a href="https://www.google.com/url?sa=i&url=https%3A%2F%2Fmakeagif.com%2Fgif%2Fphotoplethysmogram-pulse-meter-Tr2Rrc&psig=AOvVaw3Ew1IMqFg3uq6n_tYijxf8&ust=1715763597800000&source=images&cd=vfe&opi=89978449&ved=0CBEQjRxqFwoTCNj8j9DjjIYDFQAAAAAdAAAAABAE" >
								<img data-src="./Images/finger_rppg.gif">
							</a>
					  </div>
					  </figure>
					  <li class="fragment" > Remotephotophlethosmogrpahy(rPPG)</li>
					</ul>
					<figure class="image-right">
						<a href="https://www.uni-bielefeld.de/fakultaeten/technische-fakultaet/arbeitsgruppen/multimodal-behavior-processing/research/rppg/" >
							<img class="fragment r-strech" data-src="./Images/rppg_mobile.jpeg" class="image-right" >
						</a>
					</figure>
					<!-- <div class="block fragment" > -->
						<!-- Goal: Explore how changes in illumination impact the methods. -->
					<!-- </div> -->
				</section>

				<section data-auto-animate class="text-left">
					<h3 > 
						<div data-id="3" style="display: inline;"> Introduction </div>
					</h3>
					<center>
						<figure>
							<img data-src="./Images/Overview_deep.png" class="r-frame">
							<figcaption><small> Fig 1. Predicting HR from videos (Dasari et al., 2021) </small></figcaption>
						</figure>
					</center>
				</section>

				<section data-auto-animate >
					<h3 > 
						<div data-id="3" style="display: inline;"> Challenges in rPPG </div>
					</h3>
				</section>
				<section data-auto-animate>
					<h3 > 
						<div data-id="3" style="display: inline;"> Challenges in rPPG </div>
					</h3>
					<div class="icon-set">
						<div class="icon-item fragment fade-in-then-semi-out">
							<div class="icon">
								<div class="symbol">üèÉ‚Äç‚ôÇÔ∏è</div> <!-- Motion -->
							</div>
							<div class="subtitle">Motion</div>
						</div>
						<div class="icon-item fragment">
							<div class="icon">
								<div class="symbol">üí°</div> <!-- Illumination -->
							</div>
							<div class="subtitle">Illumination</div>
						</div>
						<div class="icon-item fragment fade-in-then-semi-out">
							<div class="icon">
								<div class="symbol">üë®üèΩ</div> <!-- Skin Tone -->
							</div>
							<div class="subtitle">Skin Tone</div>
						</div>
						<div class="icon-item fragment fade-in-then-semi-out">
							<div class="icon">
								<div class="symbol">üìÅ</div> <!-- Compression -->
							</div>
							<div class="subtitle">Compression</div>
						</div>
						<div class="icon-item fragment ">
							<div class="icon">
								<div class="symbol">‚ù§Ô∏è‚Äçü©π</div> <!-- High Heart Rates -->
							</div>
							<div class="subtitle">High Heart Rates</div>
						</div>
					</div>
					<!-- <figure> -->
						<!-- <img data-src="./Images/challenges.png" -->
					<!-- </figure> -->
				</section>

				<section data-auto-animate>
					<section>
					<h3 > 
						<div data-id="4" style="display: inline;"> C-PPG </div>
					</h3>
					<figure>
						<img src="./Images/protocol.png" class="r-frame" height="300">
						<figcaption><small> Fig 2. Data collection protocol </small></figcaption>
					</figure>
					</section>
					<section>
						<figure>	
							<img src="./Images/hr-dist.png", height="400", class="r-frame">
							<figcaption><small> Fig 3. HR Distribution </small></figcaption>
						</figure>
					</section>
				</section>

				<!--Slide Datasets-->
				<section data-auto-animate>
					<div class="columns">
						<div class="column">
							<ul>
								<li data-id="4"> C-PPG </li>
								<ul>
									<li > 45 participants </li>
									<li > 4 scenarios </li>
								</ul>
							</ul>
						</div>
						<div class="column">
							<ul>
								<li data-id="5"> Public Dataset</li>
								<ul>
									<li > COHFACE (Heusch et al., 2016) </li>
									<ul>
										<li>40 participants </li>
										<li >2 scenarios </li>
									</ul>
									<li > PURE (Sticker et al., 2014)</li>
									<ul>
										<li> 10 participants </li>
										<li > 6 scenarios </li>
									</ul>
								</ul>
							</ul>
						</div>
					  </div>
				</section>
				</section>
				<section >
					<H4> Methods</H4>
					<div class="columns">
						<div class="column">
					<ul>
						<li> Deep Learning</li>
						<ul>
							<li> 	Physnet  (Yu et al., 2019)    </li>
							<li>     rPPGnet  (Yu et al., 2019)    </li>
							<li>	 Physformer (Yu et al., 2023)  </li>
							<li>	 DeepPhys  (Chen et al., 2018) </li>
							<li>	 TS-CAN ( Liu et al., 2020)    </li>
						</ul>
					</ul>
						</div>
					<div class="column">
					<ul>
						<li> Classical methods</li>
						<ul>
							<li> ICA (Poh et al., 2010)         </li>
							<li> POS (Wang et al., 2016)        </li>
							<li> CHROM (Haan et al., 2013)      </li>
							<li> GREEN (Verkruysse et al., 2008)</li>
						</ul>
					</ul>
					</div>
				</section>

				<!--Slide 14-->
				<section data-auto-animate class="text-left">
					<h3>Experiments</h3>
						<ul>
						  <li class data-fragment-index="1" data-id="6">Exp 1: Evaluation of Classical and DL Methods on all Datasets </li>
						  <li class data-fragment-index="2" data-id="7">Exp 2: Generalization of DL Models Trained on Public Datasets to C-PPG </li>
						</ul>
				</section>
				<section data-auto-animate >
					<section data-auto-animate>
						<ul class="text-left">
							<li data-id="6" >Exp 1: Evaluation of Classical and DL Methods on all Datasets </li>
							<ul>
								<li> DL methods: 10 fold cross validation </li>
							</ul>
						</ul>
						<figure>
							<img data-src="./Images/exp1.png", height="400">
							<figcaption><small> Table 1. 10 fold cross validation on all datasets </small></figcaption>
						</figure>
						<!-- <div> -->
							<!-- <img data-src="./Images/nested-cv.png", height="400"> -->
						<!-- </div> -->
					</section>
					<section>
						<figure>
							<img data-src="./Images/exp1-fig2.png", height="400", class="r-frame">
							<figcaption><small> Fig 3. MAE for different scenarios of the dataset </small></figcaption>
						</figure>
					</section>
					<!-- <section data-auto-animate> -->
						<!-- <ul class="text-left"> -->
							<!-- <li data-id="6" >Exp 1: Evaluation of Classical and DL Methods on all Datasets </li> -->
						<!-- </ul> -->
						<!-- <div> -->
							<!-- <img data-src="./Images/exp1-cmbp.png", height="400"> -->
							<!-- <h4>Table 2. MAE for methods on C-PPG for different scenarios </h4> -->
						<!-- </div> -->
					<!-- </section> -->
				</section>

				<section data-auto-animate >
					<section data-auto-animate class="text-left">
						<ul>
						  	<li data-id="7">Exp 2: Generalization of DL Models Trained on Public Datasets to C-PPG </li>
							<ul>
								<li> Train on COHFACE and PURE</li>
								<li> Test on C-PPG</li>
							</ul>
						</ul>
					</section>
					<section data-auto-animate>
						<ul>
						  	<li data-id="7">Exp 2: Generalization of DL Models Trained on Public Datasets to C-PPG </li>
						</ul>
						<figure>
							<img data-src="./Images/exp2.png", height="400">
							<figcaption><small> Table 2. MAE of deep learning and classical tested on C-PPG </small></figcaption>
						</figure>
					</section> 
				</section>

				<section class="text-left">
					<h3> Key points</h3>
					<ul>
						<li>No overall best model. </li>
						<li>The results do not have a overall trend for low and high illumination. </li>
						<li>The classical methods perform well for our dataset. </li>	
						<li>Generalisation of models trained on public datasets is good for specific models but still lower than classical methods.</li>
					</ul>
				</section>

				<section class="text-left">
					<h3>Next steps</h3>
					<ul>
						<li> Continue collection of the dataset. </li>
						<li> Explore uncertainty estimation for rPPG/ HR. </li>
						<li> New Dataset with skin-tone variation. </li>
						<li> Use the HR for other downstream tasks. </li>
					</ul>
				</section>
				
				<!-- <section data-auto-animate class="text-left"> -->
					<!-- <h4> Estimating the frequency response</h4> -->
					<!-- <ul> -->
						<!-- <li> Periodogram</li> -->
						<!-- <li> Welch</li> -->
						<!-- <img src="./Images/welch_fft.svg" , height="400"> -->
					<!-- </ul> -->
				<!-- </section> -->
				<!-- <section data-auto-animate> -->
					<!-- <h3 data-id = 11 > Next steps</h3> -->
				<!-- </section> -->
				</section>
				<!-- <section data-background-iframe="https://www.uni-bielefeld.de/fakultaeten/technische-fakultaet/arbeitsgruppen/multimodal-behavior-processing/" data-background-interactive> -->
				<section class="r-fit-text">
					<h3> Thank You for your attention!</h3>
					Email: bacharya@techfak.uni-bielefeld.de
				</section>
				<section class="text-left">
					<h> References</h>
					<small>
					<ul>
					<li> Heusch, G., Anjos, A., & Marcel, S. (2017). A reproducible study on remote heart rate measurement. arXiv preprint arXiv:1709.00962.                                                                                                                                                 </li>
                                                                                                                                                                                                                                                                                              
					<li> Stricker, R., M√ºller, S., & Gross, H. M. (2014, August). Non-contact video-based pulse rate measurement on a mobile service robot. In The 23rd IEEE International Symposium on Robot and Human Interactive Communication (pp. 1056-1062). IEEE.                                     </li>
					                                                                                                                                                                                                                                                                                         
					<li> Chen, W., & McDuff, D. (2018). Deepphys: Video-based physiological measurement using convolutional attention networks. In Proceedings of the european conference on computer vision (ECCV) (pp. 349-365).                                                                           </li>
                                                                                                                                                                                                                                                                                              
					<li> Yu, Z., Li, X., & Zhao, G. (2019). Remote photoplethysmograph signal measurement from facial videos using spatio-temporal networks. arXiv preprint arXiv:1905.02419.                                                                                                                </li>
                                                                                                                                                                                                                                                                                              
					<li> Yu, Z., Peng, W., Li, X., Hong, X., & Zhao, G. (2019). Remote heart rate measurement from highly compressed facial videos: an end-to-end deep learning solution with video enhancement. In Proceedings of the IEEE/CVF international conference on computer vision (pp. 151-160).   </li>
                                                                                                                                                                                                                                                                                              
					<li> Yu, Zitong, et al. "Physformer: Facial video-based physiological measurement with temporal difference transformer." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022.                                                                        </li>
                                                                                                                                                                                                                                                                                              
					<li> Liu, X., Fromm, J., Patel, S., & McDuff, D. (2020). Multi-task temporal shift attention networks for on-device contactless vitals measurement. Advances in Neural Information Processing Systems, 33, 19400-19411.                                                                  </li>
					                                                                                                                                                                                                                                                                                         
					</ul>
					</small>
				</section>
				<section class="text-left">
					<h4> References </h4>
					<small>
						<ul>
					<li> Wang, W., Den Brinker, A. C., Stuijk, S., & De Haan, G. (2016). Algorithmic principles of remote PPG. IEEE Transactions on Biomedical Engineering, 64(7), 1479-1491.                                                                                                                </li>
                                                                                                                                                                                                                                                                                              
					<li> De Haan, G., & Jeanne, V. (2013). Robust pulse rate from chrominance-based rPPG. IEEE transactions on biomedical engineering, 60(10), 2878-2886.                                                                                                                                    </li>
                                                                                                                                                                                                                                                                                              
					<li> Poh, M. Z., McDuff, D. J., & Picard, R. W. (2010). Advancements in noncontact, multiparameter physiological measurements using a webcam. IEEE transactions on biomedical engineering, 58(1), 7-11.                                                                                  </li>
                                                                                                                                                                                                                                                                                              
					<li> Verkruysse, W., Svaasand, L. O., & Nelson, J. S. (2008). Remote plethysmographic imaging using ambient light. Optics express, 16(26), 21434-21445.                                                                                                                                  </li>
						</ul>
					</small>
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				controls: true,
            	controlsTutorial: false,
            	progress: false,
            	slideNumber: "c",
            	hashOneBasedIndex: false,
            	hash: true,
            	embedded: false,
            	showNotes: false,
            	transition: "none",
            	transitionSpeed: "default",
            	backgroundTransition: "fade",
            	pdfSeparateFragments: true,
            	autoAnimateDuration: 0.3,
				autoAnimateEasing: 'ease-out',
				autoAnimatedUnmatched: false,

            	margin: 0.04,
            	width: 1280,
            	height: 720,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
